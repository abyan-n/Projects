{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center> <h1> DS 3000 </h1> </center>\n",
    "<center> <h1> Homework Assignment 8</h1> </center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center> <h3> insert your full name here by double-clicking </h3></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy/paste the Google Colab link here as a comment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What to do\n",
    "\n",
    "* Carefully read the description.\n",
    "* As you write your code for each question, please include comments. \n",
    "* Make sure you execute your code for each question and compare the output to the sample output provided.\n",
    "* Refrain from using advanced Python capabilities/libraries that had not been covered in class when the assignment was released.\n",
    "* When in doubt, ASK! Post a question on the Piazza discussion forum for this homework assignment. \n",
    "    * But do make sure you have read all the instructions first.\n",
    "    * Please note that if we don't give you a direct answer, it's because we'd like to avoid spoonfeeding you, which is detrimental to learning.\n",
    "* Complete the assignment on your own\n",
    "* Read everything carefully.\n",
    "\n",
    "\n",
    "* If you find yourself feeling overwhelmed or distressed while working on the HW, **take a break!** \n",
    "* Watch something fun, exercise/stretch, listen to something that helps you calm down, bake something, eat chocolate, etc. Most of the time all you need is to distance yourself from the assignment and come back to it with a fresh set of eyes. \n",
    "* Avoid letting a single question/assignment get the better of you. You got this!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What to submit\n",
    "* When you are done with the assignment, save it.\n",
    "* If using Colab, download it as a **Jupyter Notebook** file (DS3000_HW8_YourName.ipynb)\n",
    "* If using Anacoda, upload your completed Notebook to Colab (https://colab.research.google.com/notebooks/).\n",
    "\n",
    "\n",
    "* Get a shareable link to your Notebook on Colab\n",
    "    * Go to Share near the top-right corner of the screen.\n",
    "    * <font color='red'> **Make sure you select Anyone with the Link Can View** </font>\n",
    "    * Copy and paste the link into the Colab link cell at the top of this document.\n",
    "    * Download your Notebook file from Google Colab, with the Google Colab link pasted into the top cell \n",
    "        * yes, it sounds like inception!\n",
    "        \n",
    "        \n",
    "* Go to Canvas\n",
    "* **Upload your Jupyter Notebook through the assignment link, which is integrated with GradeScope.** \n",
    "\n",
    "\n",
    "* You can submit multiple attempts. The last attempt will be graded.\n",
    "* Submissions failing to follow these instructions will receive a grade of 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h1> Fake News! </h1></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this assignment, you are going to prototype a fake news detector application. The attached dataset contains headlines from online resources along with a Label indicating whether the headline represents Fake News (0) or Real News (1). Your task is to train an ML model to detect Fake News based on the text included in the headline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Go ahead and import the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Headline</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Says the Annies List political group supports ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Health care reform legislation is likely to ma...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Chicago Bears have had more starting quart...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>When Mitt Romney was governor of Massachusetts...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>McCain opposed a requirement that the governme...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4549</th>\n",
       "      <td>Says Barack Obama promised to halve the defici...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4550</th>\n",
       "      <td>I am the only senator who turned down the stat...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4551</th>\n",
       "      <td>There is no system to vet refugees from the Mi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4552</th>\n",
       "      <td>I think its seven or eight of the California s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4553</th>\n",
       "      <td>Says the governor is going around the state ta...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4554 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Headline  Label\n",
       "0     Says the Annies List political group supports ...      0\n",
       "1     Health care reform legislation is likely to ma...      0\n",
       "2     The Chicago Bears have had more starting quart...      1\n",
       "3     When Mitt Romney was governor of Massachusetts...      0\n",
       "4     McCain opposed a requirement that the governme...      1\n",
       "...                                                 ...    ...\n",
       "4549  Says Barack Obama promised to halve the defici...      1\n",
       "4550  I am the only senator who turned down the stat...      1\n",
       "4551  There is no system to vet refugees from the Mi...      0\n",
       "4552  I think its seven or eight of the California s...      0\n",
       "4553  Says the governor is going around the state ta...      0\n",
       "\n",
       "[4554 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv(\"https://raw.githubusercontent.com/yildirimcaglar/yildirimcaglar.github.io/master/ds3000/fake_news_data.csv\")\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2501\n",
       "1    2053\n",
       "Name: Label, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# here are the target value counts\n",
    "data[\"Label\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1 (4pts). \n",
    "\n",
    "As you can see the dataset is not perfectly balanced. For a binary classification problem like this, it's better to have a roughly balanced dataset. Therefore, we will need to downsample the false headlines and use 2050 headlines from each class.\n",
    "\n",
    "Write a function to randomly sample an equal number of true and false headlines from the data dataframe. Your function will be generic and should work with any dataframe as described and illustrated below:\n",
    "\n",
    "- The function should receive the dataframe, name of the grouping column, and the number of samples to be drawn\n",
    "- The function should return a dataframe containing an equal number (n) of each unique value contained in the grouping column (column) randomly selected from the original dataframe (df). \n",
    "- Refer to the sample function call.\n",
    "\n",
    "Hint: You'll need to use the sample method of the dataframe object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_df_equally_by_group(df, column, n):\n",
    "    \n",
    "    g = df.groupby(column).sample(n)\n",
    "    \n",
    "    \n",
    "    return g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data = sample_df_equally_by_group(df=data, column=\"Label\", n=2050)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Headline</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3079</th>\n",
       "      <td>The Colorado caucus system for selecting Repub...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>971</th>\n",
       "      <td>Says that under City Council Member Randi Shad...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2633</th>\n",
       "      <td>George Allens flat tax plan would actually shr...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3418</th>\n",
       "      <td>The sequester has already lost 1.6 million jobs.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>528</th>\n",
       "      <td>Says that if Texas, California and New York al...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3094</th>\n",
       "      <td>On oil drilling</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4261</th>\n",
       "      <td>Sen. McCain was already turning his sights to ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2580</th>\n",
       "      <td>The 2012 National Survey on Drug Use and Healt...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999</th>\n",
       "      <td>I became a Republican sooner in my life than R...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4503</th>\n",
       "      <td>Theres almost 1 million Texans who are unemplo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4100 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Headline  Label\n",
       "3079  The Colorado caucus system for selecting Repub...      0\n",
       "971   Says that under City Council Member Randi Shad...      0\n",
       "2633  George Allens flat tax plan would actually shr...      0\n",
       "3418   The sequester has already lost 1.6 million jobs.      0\n",
       "528   Says that if Texas, California and New York al...      0\n",
       "...                                                 ...    ...\n",
       "3094                                    On oil drilling      1\n",
       "4261  Sen. McCain was already turning his sights to ...      1\n",
       "2580  The 2012 National Survey on Drug Use and Healt...      1\n",
       "2999  I became a Republican sooner in my life than R...      1\n",
       "4503  Theres almost 1 million Texans who are unemplo...      1\n",
       "\n",
       "[4100 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are the final counts in the sampled dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2050\n",
       "1    2050\n",
       "Name: Label, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_data[\"Label\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2 (7pts).\n",
    "\n",
    "Before analyzing the data, you will produce a word cloud for the true and false headlines. A word cloud is a nice way to visualize the frequent words appearing in a piece of text. \n",
    "\n",
    "For this visualization, you're going to use the StyleCloud library:\n",
    " - https://github.com/minimaxir/stylecloud\n",
    "\n",
    "You'll first need to install the library by referring to the documentation.\n",
    "\n",
    "Study the documentation carefully. The first sample shows you how to produce a word cloud from a text file:\n",
    " - https://github.com/minimaxir/stylecloud#usage\n",
    " \n",
    "Instead of specifying a file, you can also specify the text directly. For this purpose, you'll need to use the **text** keyword argument and specify the text that you want to visualize. \n",
    "\n",
    "By default, the word cloud is saved in the save directory as your Notebook file. Once you've executed your code, check that folder. The default file name is \"stylecloud.png\". You can specify the output name using the output_name keyword argument.\n",
    "\n",
    "\n",
    "For this question, produce one word cloud for all true headlines (named \"vis_true_headlines.png\") and another for all false headlines (named \"vis_false_headlines.png\") contained in the final_data dataframe. The names of the files must be specified in your code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import stylecloud\n",
    "\n",
    "true_df = final_data[final_data['Label'] == 0]\n",
    "\n",
    "tr_tx = true_df[\"Headline\"].values\n",
    "\n",
    "tr_f = ''.join(tr_tx)\n",
    "\n",
    "false_df = final_data[final_data['Label'] == 1]\n",
    "\n",
    "fa_tx = true_df[\"Headline\"].values\n",
    "\n",
    "fa_f = ''.join(fa_tx)\n",
    "\n",
    "\n",
    "true_sc = stylecloud.gen_stylecloud(text=tr_f,\n",
    "                          output_name=\"vis_true_headlines.png\")\n",
    "\n",
    "\n",
    "\n",
    "false_sc = stylecloud.gen_stylecloud(text=fa_f,\n",
    "                          output_name=\"vis_false_headlines.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the word cloud of the true headlines (yours might differ):\n",
    "<img src=\"https://i.ibb.co/y6DpWfc/vis-true-headlines.png\" alt=\"vis-true-headlines\" width=300>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the word cloud of the false headlines:\n",
    "<img src=\"https://i.ibb.co/6F6GNTp/vis-false-headlines.png\" alt=\"vis-false-headlines\" width=300>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FALSE Cloud\n",
    "\n",
    "<img src=\"https://i.ibb.co/kgbRKvh/vis-false-headlines.png\" alt=\"vis-false-headlines\" width=300>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TRUE Cloud\n",
    "\n",
    "<img src=\"https://i.ibb.co/3rX79N7/vis-true-headlines.png\" alt=\"vis-false-headlines\" width=300>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3 (3pts).\n",
    "Write a function to get the features and target variables from the final_data dataframe and obtain your training and test splits. The function should receive the dataframe and the names of the feature and target columns. Then it should return the splits as shown in the sample output. Use random_state=3000 when splitting your data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(df, feature_column, target_column):\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    \n",
    "    features = df[feature_column]\n",
    "    target = df[target_column]\n",
    "    \n",
    "    return train_test_split(features, target, random_state=3000)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = split_data(df=final_data, \n",
    "                                              feature_column=\"Headline\", \n",
    "                                              target_column=\"Label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3075,)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1025,)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4 (6pts).\n",
    "\n",
    "Write a function that can be used to vectorize text using the bag-of-words approach. \n",
    "\n",
    "- The function should receive the training set and testing set features as arguments.\n",
    "- The third argument should be the vectorizer, with two possible values: 'count' for CountVectorizer and 'tfidf' for TfidfVectorizer. The default vectorizer should be tfidf.\n",
    "- The function should construct the vocabulary based on the training set, which should then be used to represent both the training and testing sets. The vectorized training and testing sets should be returned as a tuple at the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_vectorizer(train_set, test_set, vectorizer):\n",
    "    from sklearn.feature_extraction.text import CountVectorizer\n",
    "    from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "    \n",
    "    if vectorizer == \"count\":\n",
    "        vect = CountVectorizer().fit(train_set)\n",
    "\n",
    "        X_train_vectorized = vect.transform(train_set)\n",
    "        X_test_vectorized = vect.transform(test_set)\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        vect = TfidfVectorizer().fit(X_train)\n",
    "\n",
    "        X_train_vectorized = vect.transform(train_set)\n",
    "        X_test_vectorized = vect.transform(test_set)\n",
    "        \n",
    "    return (X_train_vectorized, X_test_vectorized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_vectorized, X_test_vectorized = text_vectorizer(train_set=X_train, \n",
    "                                                        test_set=X_test, \n",
    "                                                        vectorizer = \"tfidf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3075, 6892)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_vectorized.toarray().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1025, 6892)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_vectorized.toarray().shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 5 (5pts).\n",
    "\n",
    "Write a code snippet to apply LogisticRegression, MultinomialNB, and DecisionTreeClassifier algorithms to the vectorized data. The model performance must be evaluated on the testing set. Your code must use an iteration statement to apply and evaluate multiple algorithms. Refer to the sample output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression: \n",
      "\tR-squared value for training set: 0.8504065040650407\n",
      "\tR-squared value for testing set: 0.6224390243902439\n",
      "\n",
      "Multinomial Naive Bayes: \n",
      "\tR-squared value for training set: 0.8819512195121951\n",
      "\tR-squared value for testing set: 0.6117073170731707\n",
      "\n",
      "Decision Tree: \n",
      "\tR-squared value for training set: 0.9996747967479674\n",
      "\tR-squared value for testing set: 0.5521951219512196\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "estimators = {\n",
    "    'Logistic Regression': LogisticRegression(),\n",
    "    'Multinomial Naive Bayes': MultinomialNB(),\n",
    "    'Decision Tree': DecisionTreeClassifier()}\n",
    "\n",
    "for estimator_name, estimator_object in estimators.items():\n",
    "    \n",
    "        \n",
    "        model = estimator_object.fit(X=X_train_vectorized, y=y_train)\n",
    "        \n",
    "    \n",
    "        print(estimator_name + \": \\n\\t\" + \n",
    "              f'R-squared value for training set: {model.score(X_train_vectorized, y_train)}' + \"\\n\\t\" +\n",
    "             f'R-squared value for testing set: {model.score(X_test_vectorized, y_test)}' + \"\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 6 (5pts).\n",
    "\n",
    "Based on the quick results from the previous question, it seems that the Logistic Regression is probably the best choice for this problem. For this question, you will train a Logistic Regression algorithm again, but this time you'll modify some of the parameters when extracting the features. More specifically, you should include a word in your vocabulary if it has a minimum document frequency of 5. You should also extract ngrams up to bigrams (which includes both unigrams and bigrams). Finally, you should eliminate English stop words from your vocabulary.\n",
    "\n",
    "Refer to the sample output showing model performance after modifying these parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification accuracy on training set:  0.7778861788617886\n",
      "Classification accuracy on testing set:  0.6068292682926829\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "\n",
    "\n",
    "vect = TfidfVectorizer(min_df=5, ngram_range=(1,2), stop_words = \"english\").fit(X_train)\n",
    "\n",
    "\n",
    "X_train_vectorized = vect.transform(X_train)\n",
    "X_test_vectorized = vect.transform(X_test)\n",
    "\n",
    "model = LogisticRegression().fit(X=X_train_vectorized, y=y_train)\n",
    "\n",
    "print(\"Classification accuracy on training set: \",model.score(X_train_vectorized, y_train))\n",
    "      \n",
    "print(\"Classification accuracy on testing set: \",model.score(X_test_vectorized, y_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 7 (5pts).\n",
    "\n",
    "In this last question, you will write a function that can take a headline as a string and return whether it's Real or Fake News. The function should also return the probability associated with the decision, as a measure of the confidence in the prediction.\n",
    "\n",
    "The prediction must be based on the Logistic Regression model trained in the previous question.\n",
    "\n",
    "Refer to the sample function calls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def headline_checker(headline):\n",
    "    \n",
    "    headline_features = vect.transform(headline)\n",
    "    \n",
    "    sentiment = model.predict(headline_features)\n",
    "    \n",
    "    p_list = model.predict_proba(headline_features)\n",
    "    \n",
    "    if sentiment == 1:\n",
    "        print(\"Model classification: Real News\\n Probability: %.2f\" % (p_list[0][1]))\n",
    "    else:\n",
    "        print(\"Model classification: Fake News\\n Probability: %.2f\" % (p_list[0][0]))\n",
    "    \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model classification: Real News\n",
      " Probability: 0.76\n"
     ]
    }
   ],
   "source": [
    "headline_checker([\"The State adds new vaccine requirement for senate members\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model classification: Fake News\n",
      " Probability: 0.79\n"
     ]
    }
   ],
   "source": [
    "headline_checker([\"Wisconsin Governer says he will never campaign again\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And just like that you're done with DS3000 HWs!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
